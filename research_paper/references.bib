@article{wang2024,
  title={A Survey on Large Language Model based Autonomous Agents},
  author={Wang, Lei and Ma, Chen and Feng, Xueyang and Zhang, Zeyu and Yang, Hao and Zhang, Jingsong and Chen, Zhiyuan and Tang, Jiakai and Chen, Xu and Lin, Yankai and others},
  journal={Frontiers of Computer Science},
  year={2024}
}

@inproceedings{yao2023,
  title={React: Synergizing reasoning and acting in language models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2023}
}

@article{wei2024,
  title={Jailbroken: How Does LLM Safety Training Fail?},
  author={Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob},
  journal={Advances in Neural Information Processing Systems},
  year={2024}
}

@article{qi2023,
  title={Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!},
  author={Qi, Xiangyu and Zeng, Yi and Xie, Tinghao and Chen, Pin-Yu and Jia, Ruoxi and Mittal, Prateek and Henderson, Peter},
  journal={arXiv preprint arXiv:2310.03693},
  year={2023}
}

@article{shinn2023,
  title={Reflexion: Language agents with verbal reinforcement learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  journal={arXiv preprint arXiv:2303.11366},
  year={2023}
}

@article{askell2021,
  title={A general language assistant as a laboratory for alignment},
  author={Askell, Amanda and Bai, Yuntao and Chen, Anna and Drain, Dawn and Ganguli, Deep and Henighan, Tom and Jones, Andy and Joseph, Nicholas and Mann, Ben and DasSarma, Nova and others},
  journal={arXiv preprint arXiv:2112.00861},
  year={2021}
}

@article{park2023,
  title={Generative agents: Interactive simulacra of human behavior},
  author={Park, Joon Sung and O'Brien, Joseph C and Cai, Carrie J and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  journal={Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
  year={2023}
}

@article{ouyang2022,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{bai2022,
  title={Constitutional AI: Harmlessness from AI Feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal={arXiv preprint arXiv:2212.08073},
  year={2022}
}

@inproceedings{abadi2016,
  title={Deep learning with differential privacy},
  author={Abadi, Martin and Chu, Andy and Goodfellow, Ian and McMahan, H Brendan and Mironov, Ilya and Talwar, Kunal and Zhang, Li},
  booktitle={Proceedings of the 2016 ACM SIGSAC conference on computer and communications security},
  pages={308--318},
  year={2016}
}

@inproceedings{stooke2020,
  title={Responsive safety in reinforcement learning by pid lagrangian methods},
  author={Stooke, Adam and Achiam, Joshua and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning},
  pages={9133--9143},
  year={2020},
  organization={PMLR}
}

@article{zhou2024agent,
  title={Agent Safety: A Survey on Risks and Defenses for LLM Agents},
  author={Zhou, Liangming and Xu, Hongjin and Wang, Zhiyuan and Liu, Yixin and Huang, Sheng and Jiang, Hao and others},
  journal={arXiv preprint arXiv:2402.15854},
  year={2024}
}

@inproceedings{wen2024red,
  title={Red Teaming Language Model Agents with Autonomous Adversaries},
  author={Wen, Chen and Huang, Yuchen and Zhang, Hongyang and Lee, Hung-Yi},
  booktitle={Proceedings of EMNLP},
  year={2024}
}

@inproceedings{dai2024safe,
  title={Safe RLHF: Safe Reinforcement Learning from Human Feedback},
  author={Dai, Josef and Pan, Xuehai and Sun, Ruiyang and Ji, Jiaming and Xu, Xinbo and Yu, Mickel and Wang, Yizhou and Yang, Yaodong},
  booktitle={International Conference on Learning Representations},
  year={2024},
  note={arXiv:2310.12773, ICLR 2024 Spotlight}
}

@inproceedings{pan2024rag,
  title={RAG-LLM Agents with Privacy-Preserving Memory},
  author={Pan, Xiaoman and Zhang, Yuning and Gupta, Mayank and Singh, Sameer},
  booktitle={Proceedings of NAACL},
  pages={1420--1435},
  year={2024}
}

@inproceedings{li2023pii,
  title={PII Detection and Redaction in Conversational {AI} Using Context-Aware {NER}},
  author={Li, Xiang and Zhang, Yue and Li, Jiwei},
  booktitle={Proceedings of EMNLP},
  pages={11212--11226},
  year={2023}
}

@article{liu2024constrained,
  title={Constrained Policy Optimization for Safe Language Agents},
  author={Liu, Yifan and Zhang, Tianjun and Jordan, Michael I and Stoica, Ion},
  journal={arXiv preprint arXiv:2401.09984},
  year={2024}
}

@inproceedings{chen2022convfinqa,
  title={FinQA: A Dataset of Numerical Reasoning over Financial Data},
  author={Chen, Zhiyu and Chen, Wenhu and Smiley, Charese and Shah, Sameena and Borova, Iana and Langdon, Dylan and Moussa, Reema and Beane, Matt and Huang, Ting-Hao and Routledge, Bryan and Wang, William Yang},
  booktitle={Proceedings of EMNLP},
  year={2022}
}

@article{ji2024beavertails,
  title={BeaverTails: Towards Improved Safety Alignment of LLM via a Human-Preference Dataset},
  author={Ji, Jiaming and Liu, Mickel and Dai, Josef and Pan, Xuehai and Zhang, Chi and Bian, Ce and Chen, Boyuan and Sun, Ruiyang and Wang, Yizhou and Yang, Yaodong},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}

@inproceedings{allen2019convergence,
  title={A Convergence Theory for Deep Learning via Over-Parameterization},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao},
  booktitle={International Conference on Machine Learning},
  pages={242--252},
  year={2019},
  organization={PMLR}
}
